# Medi-AI: Full-Stack Medical AI Assistant ğŸ¥

A production-ready full-stack medical assistance application with Next.js frontend and FastAPI backend, powered by OpenAI GPT-4o and ElevenLabs voice synthesis.

## ğŸŒŸ Features

### AIRA - AI Responsive & Intelligent Assistant
Your comprehensive medical AI assistant that can help with:
- ğŸ©º Symptom analysis and health guidance
- ğŸ“… Appointment scheduling support
- ğŸ’Š Medication information
- ğŸƒ Health coaching
- ğŸš¨ Emergency guidance
- ğŸ—£ï¸ Natural voice conversations

### Backend (FastAPI)
- **OpenAI GPT-4o**: Advanced AI chat completion
- **OpenAI Whisper**: Speech-to-text transcription
- **ElevenLabs**: Natural text-to-speech synthesis
- **FastAPI Framework**: Modern, fast, high-performance
- **Type Safety**: Full Pydantic validation
- **Auto Documentation**: Swagger UI and ReDoc
- **CORS Support**: Configurable middleware

### Frontend (Next.js + shadcn/ui)
- **Modern Medical Dashboard**: Professional healthcare interface
- **Voice Conversations**: Full speech-to-text and text-to-speech
- **Medical Records**: Health records management
- **Appointments**: Doctor appointments tracking
- **Alerts & Reminders**: Medication and health notifications
- **Emergency Access**: Quick emergency contacts
- **Real-time AI Chat**: Instant medical assistance
- **Responsive Design**: Works on all devices

## ğŸ“ Project Structure

```
medi-ai/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI application
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â”‚   â”œâ”€â”€ routes/            # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.py      # Chat completion
â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.py  # Whisper STT
â”‚   â”‚   â”‚   â””â”€â”€ voice.py       # ElevenLabs TTS
â”‚   â”‚   â””â”€â”€ services/          # Business logic
â”‚   â”‚       â”œâ”€â”€ openai_service.py
â”‚   â”‚       â””â”€â”€ elevenlabs_service.py
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ run.py                # Server startup
â”‚   â”œâ”€â”€ .env.example          # Environment template
â”‚   â””â”€â”€ README.md             # Backend documentation
â”‚
â”œâ”€â”€ frontend/                   # Next.js Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/               # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx       # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx     # Root layout
â”‚   â”‚   â”‚   â””â”€â”€ globals.css    # Global styles
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/            # shadcn/ui components
â”‚   â”‚   â”‚   â”œâ”€â”€ MedicalDashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceCallModal.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Sidebar.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts         # API client
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ speech.d.ts    # TypeScript types
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â””â”€â”€ utils.ts       # Utilities
â”‚   â”œâ”€â”€ next.config.js
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+**
- **Node.js 18+** and npm/yarn
- **OpenAI API Key** (for GPT-4o and Whisper)
- **ElevenLabs API Key** (for voice synthesis)

## Installation

### 1. Clone Repository

```bash
git clone https://github.com/Shaik-mohd-huzaifa/medi-ai.git
cd medi-ai
```

### 2. Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
```

Edit `backend/.env` with your API keys:
```env
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.7

ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_MODEL_ID=eleven_monolingual_v1
```

### 3. Frontend Setup

```bash
# Navigate to frontend (from root)
cd frontend

# Install dependencies
npm install
# or
yarn install

# Configure environment (optional)
# Create frontend/.env.local:
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## Running the Application

### Start Backend

**From the `backend` directory:**

```bash
# Option 1: Using run script
python run.py

# Option 2: Using uvicorn directly
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend available at:
- **API**: http://localhost:8000
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Start Frontend

**From the `frontend` directory:**

```bash
npm run dev
# or
yarn dev
```

Frontend available at:
- **Application**: http://localhost:3000

### Running Both (Two Terminals)

**Terminal 1 (Backend):**
```bash
cd backend
python run.py
```

**Terminal 2 (Frontend):**
```bash
cd frontend
npm run dev
```

Then open http://localhost:3000 in your browser! ğŸ‰

## ğŸ¯ Using AIRA Voice Assistant

### Voice Conversation Flow

1. **Start Voice Call**: Click the phone icon (ğŸ“) in the top right
2. **Speak**: Click the microphone button and describe your health concern
3. **AI Processing**: 
   - Your speech â†’ Whisper API â†’ Text transcription
   - Text â†’ GPT-4o â†’ AI response
   - Response â†’ ElevenLabs â†’ Natural voice audio
4. **Listen**: AIRA responds with natural, professional voice
5. **Continue**: Click mic again to continue the conversation
6. **End Call**: Click "End Call" when finished

### Text Chat

- Type your question in the chat input at the bottom
- Press `Enter` to send
- Receive instant AI responses
- Click microphone icon for quick voice input

## ğŸ”Œ API Endpoints

### Health & Status
- `GET /` - Welcome message
- `GET /health` - Health check

### Chat & AI
- `POST /api/v1/bedrock/generate` - Generate text
- `POST /api/v1/bedrock/generate/stream` - Stream generation
- `POST /api/v1/bedrock/chat` - Chat completion

### Speech Recognition
- `POST /api/v1/transcription/whisper` - Transcribe audio to text

### Voice Synthesis
- `POST /api/v1/voice/text-to-speech` - Convert text to speech
- `POST /api/v1/voice/text-to-speech/stream` - Stream TTS
- `GET /api/v1/voice/voices` - List available voices

Full API documentation: http://localhost:8000/docs

## ğŸ”‘ Getting API Keys

### OpenAI
1. Visit https://platform.openai.com/api-keys
2. Create an account or sign in
3. Generate a new API key
4. Copy to `backend/.env` as `OPENAI_API_KEY`

### ElevenLabs
1. Visit https://elevenlabs.io/
2. Create an account or sign in
3. Navigate to Profile â†’ API Keys
4. Generate a new API key
5. Copy to `backend/.env` as `ELEVENLABS_API_KEY`

## ğŸ› ï¸ Development

### Backend Development

```bash
cd backend

# Run with auto-reload
uvicorn app.main:app --reload

# Format code
pip install black
black app/

# Type checking
pip install mypy
mypy app/
```

### Frontend Development

```bash
cd frontend

# Development server with hot reload
npm run dev

# Build for production
npm run build

# Lint code
npm run lint
```

## ğŸ“¦ Production Deployment

### Backend

**Using Docker:**
```bash
cd backend
docker build -t medi-ai-backend .
docker run -p 8000:8000 --env-file .env medi-ai-backend
```

**Using Gunicorn:**
```bash
pip install gunicorn
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000
```

### Frontend

**Build:**
```bash
cd frontend
npm run build
```

**Deploy to:**
- **Vercel**: `vercel deploy`
- **Netlify**: Deploy `.next` folder
- **AWS S3 + CloudFront**: Upload build output

**âš ï¸ Important**: Update `NEXT_PUBLIC_API_URL` to your production backend URL before building.

## ğŸ”’ Security

- âœ… Never commit `.env` files
- âœ… Use environment variables for secrets
- âœ… Configure CORS properly for production
- âœ… Implement rate limiting
- âœ… Use HTTPS in production
- âœ… Rotate API keys regularly

## ğŸ› Troubleshooting

### Backend Issues

**Cannot start server:**
```bash
# Activate virtual environment
cd backend
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Reinstall dependencies
pip install -r requirements.txt
```

**API Key errors:**
- Verify API keys in `backend/.env`
- Check keys are valid and not expired
- Ensure no extra spaces in `.env` file

### Frontend Issues

**Cannot connect to backend:**
- Verify backend is running on port 8000
- Check `NEXT_PUBLIC_API_URL` in `frontend/.env.local`
- Open http://localhost:8000/health to test backend

**Build errors:**
```bash
cd frontend
rm -rf node_modules .next
npm install
npm run dev
```

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- **OpenAI** for GPT-4o and Whisper
- **ElevenLabs** for natural voice synthesis
- **FastAPI** for the excellent framework
- **Next.js** and **shadcn/ui** for frontend tools

## ğŸ“ Support

For issues or questions:
- Open an issue on GitHub
- Check the documentation in `/backend/README.md`
- Review API docs at http://localhost:8000/docs

---

**Made with â¤ï¸ for better healthcare accessibility**
